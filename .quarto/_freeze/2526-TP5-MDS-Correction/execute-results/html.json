{
  "hash": "a0aa6ca2b6f8422d26f9dc2192b08a78",
  "result": {
    "markdown": "---\ntitle: \"TP5 - Multidimensional Scaling - Correction\"\nsubtitle: \"4modIA / 2025-2026\"\nformat:\n  html:\n    toc: true\n    toc-depth : 4\n    toc-location: left\n    number-sections: false\n    css: styles.css\n---\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(ggplot2)\nlibrary(gridExtra)\nlibrary(FactoMineR)\nlibrary(factoextra)\nlibrary(reshape2)\nlibrary(ggrepel)\nlibrary(ggfortify)\nlibrary(corrplot)\n```\n:::\n\n\n# Exercice 1 : Données simulées\n\nDans cet exercice, on va partir d'un jeu de données simulé afin de comprendre le cours sur le Multidimensional Scaling (MDS). \nOn simule un échantillon $\\mathbf Y = (Y_1,\\ldots,Y_n)$ avec $Y_i\\in\\mathbb R^5$ et $n=20$. On calcule la distance euclidienne usuelle entre chaque pair d'individus à l'aide de la fonction `dist()`. La matrice $\\mathcal D$ obtenue est visualisée à l'aide de la fonction `autoplot()` de la librairie `ggfortify`. \n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(1111)\nY<-matrix(round(runif(20*5,min=-5,max=5),0),ncol=5)\nn<-nrow(Y)\nD<-dist(Y)\nautoplot(D)\n```\n\n::: {.cell-output-display}\n![](2526-TP5-MDS-Correction_files/figure-html/unnamed-chunk-2-1.png){width=672}\n:::\n:::\n\n\nOn souhaite faire une MDS à partir de la matrice de distance $\\mathcal D=(d_{ij})$. \n\n\n**Question 1:** Programmez les matrices $A = (-\\frac 1 2 d_{ij}^2)$, $H=I_n - \\frac 1 n \\mathbb{1}_n \\mathbb{1}^\\top$ et $B=H A H^\\top$. \n\n\n::: {.cell}\n\n```{.r .cell-code}\nA<- ...\nH<- ...\nB<- ...\n```\n:::\n\n\n\n:::{.callout-note custom-style=\"correction\" appearance=\"simple\" title=\"Correction\"}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nA<-(-0.5)*(as.matrix(D)^2)\nH<-diag(1,nrow(Y)) - matrix(1/n,nrow=n,ncol=n)\nB<-H%*%A%*%t(H)\n```\n:::\n\n:::\n\n**Question 2:** Faites la décomposition spectrale de $B$. Que pouvez-vous dire des valeurs propres ? Tracez les valeurs propres décroissantes. \n\n\n::: {.cell}\n\n```{.r .cell-code}\n# A COMPLETER\n```\n:::\n\n\n\n:::{.callout-note custom-style=\"correction\" appearance=\"simple\" title=\"Correction\"}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nvpB<-eigen(B)\nround(vpB$values,2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n [1] 282.28 224.94 173.73  95.33  68.33   0.00   0.00   0.00   0.00   0.00\n[11]   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00\n```\n:::\n\n```{.r .cell-code}\ndf<-data.frame(dim=1:n,vp=vpB$values)\nggplot(df,aes(x=dim,y=vp))+geom_point()+geom_line()\n```\n\n::: {.cell-output-display}\n![](2526-TP5-MDS-Correction_files/figure-html/unnamed-chunk-6-1.png){width=672}\n:::\n\n```{.r .cell-code}\n# Nb de valeurs propres non nulles\nsum(round(vpB$values,10)>0)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 5\n```\n:::\n:::\n\n:::\n\n**Question 3:** Déduisez-en les coordonnées principales $X=\\{x_1,\\ldots,x_n\\}$ et tracez les individus dans l'espace euclidien retenu. \n\n\n::: {.cell}\n\n```{.r .cell-code}\nX<- ...\n# A COMPLETER\n```\n:::\n\n\n\n:::{.callout-note custom-style=\"correction\" appearance=\"simple\" title=\"Correction\"}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nX <- vpB$vectors[,1:2] %*% diag(sqrt(vpB$values[1:2]))\ncolnames(X)<-c(\"Dim1\",\"Dim2\")\nrownames(X)<-paste(\"I \",1:n,sep=\"\")\nggplot(X,aes(x=Dim1,y=Dim2))+geom_point()\n```\n\n::: {.cell-output-display}\n![](2526-TP5-MDS-Correction_files/figure-html/unnamed-chunk-8-1.png){width=672}\n:::\n:::\n\n:::\n\n**Question 4:** A l'aide de la fonction `cmdscale()`, faites une MDS sur $\\mathcal D$ et comparez avec les résultats des questions précédentes. \n\n\n::: {.cell}\n\n```{.r .cell-code}\nres<-cmdscale(.....)\n# A COMPLETER\n```\n:::\n\n\n:::{.callout-note custom-style=\"correction\" appearance=\"simple\" title=\"Correction\"}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nres<-cmdscale(D,eig = T,add = F,k = 2)\nstr(res)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nList of 5\n $ points: num [1:20, 1:2] -1.131 0.473 -0.886 -8.263 6.819 ...\n  ..- attr(*, \"dimnames\")=List of 2\n  .. ..$ : NULL\n  .. ..$ : NULL\n $ eig   : num [1:20] 282.3 224.9 173.7 95.3 68.3 ...\n $ x     : NULL\n $ ac    : num 0\n $ GOF   : num [1:2] 0.601 0.601\n```\n:::\n\n```{.r .cell-code}\nround(res$eig,2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n [1] 282.28 224.94 173.73  95.33  68.33   0.00   0.00   0.00   0.00   0.00\n[11]   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00\n```\n:::\n\n```{.r .cell-code}\nautoplot(res, label=T,label.size=4,xlab=\"\",ylab=\"\")\n```\n\n::: {.cell-output-display}\n![](2526-TP5-MDS-Correction_files/figure-html/unnamed-chunk-10-1.png){width=672}\n:::\n:::\n\n:::\n\n**Question 5:** On s'intéresse au lien entre MDS et PCA. Faites une PCA sur le jeu de données $Y$. Retrouvez le lien entre les coordonnées principales de la MDS et les composantes principales de l'ACP. \n\n\n::: {.cell}\n\n```{.r .cell-code}\nresPCA<-PCA(....)\n# A COMPLETER\n```\n:::\n\n\n:::{.callout-note custom-style=\"correction\" appearance=\"simple\" title=\"Correction\"}\n\nOn fait une ACP sur les données $Y$ avec la matrice de poids $W=\\frac 1 n I_n$ et la matrice métrique $M=I_5$. \n\n\n::: {.cell}\n\n```{.r .cell-code}\nresPCA<-PCA(Y,scale.unit = F,graph=F)\nfviz_pca_ind(resPCA)\n```\n\n::: {.cell-output-display}\n![](2526-TP5-MDS-Correction_files/figure-html/unnamed-chunk-12-1.png){width=672}\n:::\n:::\n\n\nOn retrouve les mêmes valeurs propres\n\n::: {.cell}\n\n```{.r .cell-code}\nround(n*resPCA$eig[,1],2) \n```\n\n::: {.cell-output .cell-output-stdout}\n```\ncomp 1 comp 2 comp 3 comp 4 comp 5 \n282.28 224.94 173.73  95.33  68.33 \n```\n:::\n\n```{.r .cell-code}\nround(res$eig,2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n [1] 282.28 224.94 173.73  95.33  68.33   0.00   0.00   0.00   0.00   0.00\n[11]   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00\n```\n:::\n:::\n\n\n\nEn ACP : $\\frac 1 n Y'Y u = \\lambda u \\Leftrightarrow  Y'Y u = (n \\lambda) u$\n\n\n::: {.cell}\n\n```{.r .cell-code}\nresPCA$ind$coord[,1:2]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n        Dim.1       Dim.2\n1  -1.1314246  1.91384971\n2   0.4726446 -2.49773308\n3  -0.8856930  6.93762131\n4  -8.2632649  0.31381993\n5   6.8194751 -2.88120220\n6   3.5822045  1.92348061\n7   2.9478170 -2.62088447\n8  -1.7063775 -4.91351082\n9  -3.2298517  0.03939138\n10 -0.1991892 -1.41413019\n11 -7.2125474 -2.36380358\n12 -3.4934580  2.97923290\n13 -1.5594630  1.60736554\n14 -0.2534606  2.56057315\n15  0.7278012 -2.28453635\n16 -0.7105496 -7.38223822\n17  1.5685036  5.09473547\n18  4.3721169 -1.38761947\n19  2.1130018  2.90167947\n20  6.0417148  1.47390889\n```\n:::\n\n```{.r .cell-code}\nres$points\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n            [,1]        [,2]\n [1,] -1.1314246  1.91384971\n [2,]  0.4726446 -2.49773308\n [3,] -0.8856930  6.93762131\n [4,] -8.2632649  0.31381993\n [5,]  6.8194751 -2.88120220\n [6,]  3.5822045  1.92348061\n [7,]  2.9478170 -2.62088447\n [8,] -1.7063775 -4.91351082\n [9,] -3.2298517  0.03939138\n[10,] -0.1991892 -1.41413019\n[11,] -7.2125474 -2.36380358\n[12,] -3.4934580  2.97923290\n[13,] -1.5594630  1.60736554\n[14,] -0.2534606  2.56057315\n[15,]  0.7278012 -2.28453635\n[16,] -0.7105496 -7.38223822\n[17,]  1.5685036  5.09473547\n[18,]  4.3721169 -1.38761947\n[19,]  2.1130018  2.90167947\n[20,]  6.0417148  1.47390889\n```\n:::\n:::\n\n:::\n\n# Exercice 2 : jeu de données des villes\n\nPour cet exercice, nous travaillerons sur les données `mdsville.csv`. Elles se présentent sous la forme d'une matrice symétrique triangulaire contenant les distances kilométriques routières de 47 villes françaises.\n\n**Question 1:** Lisez le fichier de données `mdsvilles.csv` et transformez en matrice de distance avec la fonction `as.dist()`.\nVisualisez la matrice de distance. \n\n\n::: {.cell}\n\n```{.r .cell-code}\nmdsvilles <- read.csv(.....)\nd<-as.dist(mdsville,diag=TRUE)\n```\n:::\n\n\n:::{.callout-note custom-style=\"correction\" appearance=\"simple\" title=\"Correction\"}\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# lecture de la table de données\nmdsville<-read.csv(\"mdsville.csv\",header=TRUE,sep=\" \", dec=\".\", stringsAsFactors = FALSE,row.names = 1)\n\n# transformation en un objet de type distance\nd <- as.dist(mdsville,diag=TRUE)\nautoplot(d) + theme( axis.text.x = element_text(angle = 72,vjust = 1, size = 9, hjust = 1))\n```\n\n::: {.cell-output-display}\n![](2526-TP5-MDS-Correction_files/figure-html/unnamed-chunk-16-1.png){width=672}\n:::\n:::\n\n:::\n\n**Question 2:** A l'aide de la fonction `cmdscale()`, faites une MDS sur la matrice distance $\\mathcal D$. \n\n\n::: {.cell}\n\n```{.r .cell-code}\nmds <- cmdscale(...)\n```\n:::\n\n\n:::{.callout-note custom-style=\"correction\" appearance=\"simple\" title=\"Correction\"}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmds <- cmdscale(d,  eig=TRUE,x.ret=TRUE)\nstr(mds)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nList of 5\n $ points: num [1:47, 1:2] 344.4 -596.3 115.1 -19.9 172.4 ...\n  ..- attr(*, \"dimnames\")=List of 2\n  .. ..$ : chr [1:47] \"amie\" \"ando\" \"ange\" \"bale\" ...\n  .. ..$ : NULL\n $ eig   : num [1:47] 4965039 4081308 759833 518622 291547 ...\n $ x     : num [1:47, 1:47] -261498 421694 -7298 -82769 3618 ...\n $ ac    : num 0\n $ GOF   : num [1:2] 0.613 0.755\n```\n:::\n:::\n\n:::\n\n**Question 3:** Etudiez le pourcentage d'inertie et d'inertie cumulée en fonction de la dimension $r$. Combien de coordonnées principales retenez-vous ?\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# A COMPLETER\n```\n:::\n\n\n:::{.callout-note custom-style=\"correction\" appearance=\"simple\" title=\"Correction\"}\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#Valeurs propres positives\neig.pos <-mds$eig[mds$eig > 0]\n\n# Pourcentage d'inertie et d'inertie cumuluée\ninertie=100*eig.pos/sum(eig.pos)\ncinertie <- 100*cumsum(eig.pos)/sum(eig.pos)\n\n#graphique\ndf<-data.frame(r=1:length(eig.pos),inertie=inertie,cinertie=cinertie)\ng1<-ggplot(df,aes(x=r,y=inertie))+geom_point()+\n  geom_line()+ylab(\"Pourcentages d'inertie\")\ng2<-ggplot(df,aes(x=r,y=cinertie))+geom_point()+\n  geom_line()+ylab(\"Pourcentages cumulés\")\ngrid.arrange(g1,g2,ncol=2)\n```\n\n::: {.cell-output-display}\n![](2526-TP5-MDS-Correction_files/figure-html/unnamed-chunk-20-1.png){width=672}\n:::\n:::\n\n:::\n\n**Question 4:** Visualisez graphiquement les coordonnées des villes. Commentez. Transposez le graphique pour plus de concordance géographique. \n\n\n::: {.cell}\n\n```{.r .cell-code}\nautoplot(mds, label=T,label.size=4,xlab=\"\",ylab=\"\")\ndf<-data.frame(x=....,y=....,Name=rownames(mds$points))\nggplot(df, aes(x= x, y = y)) + \n  geom_point() #color = \"blue\", size = 3)+ \n  geom_label_repel(aes(label = Name),\n                  box.padding   = 0.35, \n                  point.padding = 0.5,\n                  segment.color = 'grey50') +\n  theme_classic()\n```\n:::\n\n\n:::{.callout-note custom-style=\"correction\" appearance=\"simple\" title=\"Correction\"}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nautoplot(mds, label=T,label.size=4,xlab=\"\",ylab=\"\")\n```\n\n::: {.cell-output-display}\n![](2526-TP5-MDS-Correction_files/figure-html/unnamed-chunk-22-1.png){width=672}\n:::\n\n```{.r .cell-code}\ndf<-data.frame(x=(-1)*mds$points[,2],y=mds$points[,1],Name=rownames(mds$points))\nggplot(df, aes(x= x, y = y)) + \n  geom_point()+ \n  geom_label_repel(aes(label = Name),\n                  box.padding   = 0.35, \n                  point.padding = 0.5,\n                  segment.color = 'grey50') +\n  theme_classic()\n```\n\n::: {.cell-output-display}\n![](2526-TP5-MDS-Correction_files/figure-html/unnamed-chunk-22-2.png){width=672}\n:::\n:::\n\n\n:::\n\n**Question 6:** Comparez la distance restituée avec la matrice de distance initiale (via le diagramme de Shepard).\n\n\n::: {.cell}\n\n```{.r .cell-code}\nDhat<- ...\ndf<-data.frame(d=as.vector(as.matrix(d)),\n               dhat=as.vector(as.matrix(Dhat)))\nggplot(df,aes(x=d,y=dhat))+\n  geom_point()+ \n  geom_line(aes(x=d,y=d),col=\"blue\")\n```\n:::\n\n\n:::{.callout-note custom-style=\"correction\" appearance=\"simple\" title=\"Correction\"}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nDhat<-dist(mds$points)\ndf<-data.frame(d=as.vector(as.matrix(d)),dhat=as.vector(as.matrix(Dhat)))\nggplot(df,aes(x=d,y=dhat))+\n  geom_point()+ \n  geom_line(aes(x=d,y=d),col=\"blue\")\n```\n\n::: {.cell-output-display}\n![](2526-TP5-MDS-Correction_files/figure-html/unnamed-chunk-24-1.png){width=672}\n:::\n:::\n\n:::\n\n**Question 7:** Pour  dépasser  le  problème  des  valeurs  propres  négatives  de  la  matrice $B$,  une autre possibilité consiste  à ajouter une  constante  positive $c$ aux  éléments  hors  diagonale  principale. Elle  doit être  la plus   petite possible   pour   éviter   de détériorer l’information. Sa   valeur   peut   être   déterminée analytiquement. En adaptant les options de la fonction `cmdscale()`, mettez en place cette procédure. Que vaut la constante $c$ optimisée ? Comparez les résultats avec ceux des questons précédentes. \n\n\n::: {.cell}\n\n```{.r .cell-code}\nmds.bis <-cmdscale(...)\n# A completer\n```\n:::\n\n\n:::{.callout-note custom-style=\"correction\" appearance=\"simple\" title=\"Correction\"}\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#pour avoir uniquement des v.p. positives\nmds.bis <-cmdscale(d=d,eig=TRUE,add=TRUE)\nround(mds.bis$eig,2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n [1] 22971918 20489271  6985120  5230068  4578532  4046998  3517313  3362876\n [9]  3305354  3090164  2990846  2861251  2837730  2738974  2685138  2633615\n[17]  2543390  2522340  2431053  2402270  2366856  2333463  2315081  2300804\n[25]  2284303  2262027  2229652  2209960  2195316  2171661  2147011  2140408\n[33]  2104013  2060763  2041112  2021788  1992623  1977296  1947245  1900278\n[41]  1861548  1851219  1753507  1680483  1570825        0        0\n```\n:::\n:::\n\n\nOn a corrigé avec la constante $c$ qui vaut\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmds.bis$ac\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 2018.287\n```\n:::\n:::\n\n:::\n\n# Exercice 3 : Données `Spam`\n\nOn s'intéresse ici à des données textuelles. George, ingénieur chez HP dans le département Computer Science a recueilli un échantillon de messages électroniques dans chacun desquels il a évalué le nombre d'occurrences d'une sélection de mots et caractères. Les variables considérées sont dans un premier temps des rapports (nombre d'occurrences d'un mot spécifique sur le nombre total de mots ou nombre d'occurrences d'un caractère sur le nombre de caractères du message) avant d'être transformées en indicatrices ou facteurs: présence / absence de mots ou ensemble de caractères. Il a également considéré trois variables prenant en compte la casse (majuscule / minuscule) des caractères et une dernière qualitative binaire indiquant le classement qu'il a fait de chaque message : spam ou pas. Ces données sont publiques, elles servent régulièrement de benchmark pour la comparaison de méthodes d'apprentissage machine: jeu de données `spam` issu du site de l'[UCI Machine Learning Repository](https://archive.ics.uci.edu/).\n\nAu final, les données se présentent sous la forme d'un tableau contenant $p=57$ mots observés dans $n=4601$ messages dont $1813$ sont des spams.\n\n**Question 1:** Importez les données à l'aide des commandes suivantes. Faites quelques statistiques descriptives. Quelle est la principale caractéristique des variables étudiées ?\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# lecture de la table de données\nspam=read.table(\"spam.dat\",header=TRUE)\nspam[,1]=as.factor(spam[,1])\ndim(spam)\nsummary(spam)\n```\n:::\n\n\n:::{.callout-note custom-style=\"correction\" appearance=\"simple\" title=\"Correction\"}\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# lecture de la table de données\nspam=read.table(\"spam.dat\",header=TRUE)\nspam[,1]=as.factor(spam[,1])\ndim(spam)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 4601   58\n```\n:::\n\n```{.r .cell-code}\nsummary(spam)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n spam          make           address            all              X3d          \n 0:2788   Min.   :0.0000   Min.   : 0.000   Min.   :0.0000   Min.   : 0.00000  \n 1:1813   1st Qu.:0.0000   1st Qu.: 0.000   1st Qu.:0.0000   1st Qu.: 0.00000  \n          Median :0.0000   Median : 0.000   Median :0.0000   Median : 0.00000  \n          Mean   :0.1046   Mean   : 0.213   Mean   :0.2807   Mean   : 0.06542  \n          3rd Qu.:0.0000   3rd Qu.: 0.000   3rd Qu.:0.4200   3rd Qu.: 0.00000  \n          Max.   :4.5400   Max.   :14.280   Max.   :5.1000   Max.   :42.81000  \n      our               over            remove          internet      \n Min.   : 0.0000   Min.   :0.0000   Min.   :0.0000   Min.   : 0.0000  \n 1st Qu.: 0.0000   1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.: 0.0000  \n Median : 0.0000   Median :0.0000   Median :0.0000   Median : 0.0000  \n Mean   : 0.3122   Mean   :0.0959   Mean   :0.1142   Mean   : 0.1053  \n 3rd Qu.: 0.3800   3rd Qu.:0.0000   3rd Qu.:0.0000   3rd Qu.: 0.0000  \n Max.   :10.0000   Max.   :5.8800   Max.   :7.2700   Max.   :11.1100  \n     order              mail            receive             will       \n Min.   :0.00000   Min.   : 0.0000   Min.   :0.00000   Min.   :0.0000  \n 1st Qu.:0.00000   1st Qu.: 0.0000   1st Qu.:0.00000   1st Qu.:0.0000  \n Median :0.00000   Median : 0.0000   Median :0.00000   Median :0.1000  \n Mean   :0.09007   Mean   : 0.2394   Mean   :0.05982   Mean   :0.5417  \n 3rd Qu.:0.00000   3rd Qu.: 0.1600   3rd Qu.:0.00000   3rd Qu.:0.8000  \n Max.   :5.26000   Max.   :18.1800   Max.   :2.61000   Max.   :9.6700  \n     people            report           addresses           free        \n Min.   :0.00000   Min.   : 0.00000   Min.   :0.0000   Min.   : 0.0000  \n 1st Qu.:0.00000   1st Qu.: 0.00000   1st Qu.:0.0000   1st Qu.: 0.0000  \n Median :0.00000   Median : 0.00000   Median :0.0000   Median : 0.0000  \n Mean   :0.09393   Mean   : 0.05863   Mean   :0.0492   Mean   : 0.2488  \n 3rd Qu.:0.00000   3rd Qu.: 0.00000   3rd Qu.:0.0000   3rd Qu.: 0.1000  \n Max.   :5.55000   Max.   :10.00000   Max.   :4.4100   Max.   :20.0000  \n    business          email             you             credit        \n Min.   :0.0000   Min.   :0.0000   Min.   : 0.000   Min.   : 0.00000  \n 1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.: 0.000   1st Qu.: 0.00000  \n Median :0.0000   Median :0.0000   Median : 1.310   Median : 0.00000  \n Mean   :0.1426   Mean   :0.1847   Mean   : 1.662   Mean   : 0.08558  \n 3rd Qu.:0.0000   3rd Qu.:0.0000   3rd Qu.: 2.640   3rd Qu.: 0.00000  \n Max.   :7.1400   Max.   :9.0900   Max.   :18.750   Max.   :18.18000  \n      your              font              X000            money         \n Min.   : 0.0000   Min.   : 0.0000   Min.   :0.0000   Min.   : 0.00000  \n 1st Qu.: 0.0000   1st Qu.: 0.0000   1st Qu.:0.0000   1st Qu.: 0.00000  \n Median : 0.2200   Median : 0.0000   Median :0.0000   Median : 0.00000  \n Mean   : 0.8098   Mean   : 0.1212   Mean   :0.1016   Mean   : 0.09427  \n 3rd Qu.: 1.2700   3rd Qu.: 0.0000   3rd Qu.:0.0000   3rd Qu.: 0.00000  \n Max.   :11.1100   Max.   :17.1000   Max.   :5.4500   Max.   :12.50000  \n       hp               hpl              george             X650       \n Min.   : 0.0000   Min.   : 0.0000   Min.   : 0.0000   Min.   :0.0000  \n 1st Qu.: 0.0000   1st Qu.: 0.0000   1st Qu.: 0.0000   1st Qu.:0.0000  \n Median : 0.0000   Median : 0.0000   Median : 0.0000   Median :0.0000  \n Mean   : 0.5495   Mean   : 0.2654   Mean   : 0.7673   Mean   :0.1248  \n 3rd Qu.: 0.0000   3rd Qu.: 0.0000   3rd Qu.: 0.0000   3rd Qu.:0.0000  \n Max.   :20.8300   Max.   :16.6600   Max.   :33.3300   Max.   :9.0900  \n      lab                labs            telnet              X857        \n Min.   : 0.00000   Min.   :0.0000   Min.   : 0.00000   Min.   :0.00000  \n 1st Qu.: 0.00000   1st Qu.:0.0000   1st Qu.: 0.00000   1st Qu.:0.00000  \n Median : 0.00000   Median :0.0000   Median : 0.00000   Median :0.00000  \n Mean   : 0.09892   Mean   :0.1029   Mean   : 0.06475   Mean   :0.04705  \n 3rd Qu.: 0.00000   3rd Qu.:0.0000   3rd Qu.: 0.00000   3rd Qu.:0.00000  \n Max.   :14.28000   Max.   :5.8800   Max.   :12.50000   Max.   :4.76000  \n      data               X415              X85            technology     \n Min.   : 0.00000   Min.   :0.00000   Min.   : 0.0000   Min.   :0.00000  \n 1st Qu.: 0.00000   1st Qu.:0.00000   1st Qu.: 0.0000   1st Qu.:0.00000  \n Median : 0.00000   Median :0.00000   Median : 0.0000   Median :0.00000  \n Mean   : 0.09723   Mean   :0.04784   Mean   : 0.1054   Mean   :0.09748  \n 3rd Qu.: 0.00000   3rd Qu.:0.00000   3rd Qu.: 0.0000   3rd Qu.:0.00000  \n Max.   :18.18000   Max.   :4.76000   Max.   :20.0000   Max.   :7.69000  \n     X1999           parts              pm               direct       \n Min.   :0.000   Min.   :0.0000   Min.   : 0.00000   Min.   :0.00000  \n 1st Qu.:0.000   1st Qu.:0.0000   1st Qu.: 0.00000   1st Qu.:0.00000  \n Median :0.000   Median :0.0000   Median : 0.00000   Median :0.00000  \n Mean   :0.137   Mean   :0.0132   Mean   : 0.07863   Mean   :0.06483  \n 3rd Qu.:0.000   3rd Qu.:0.0000   3rd Qu.: 0.00000   3rd Qu.:0.00000  \n Max.   :6.890   Max.   :8.3300   Max.   :11.11000   Max.   :4.76000  \n       cs             meeting           original         project       \n Min.   :0.00000   Min.   : 0.0000   Min.   :0.0000   Min.   : 0.0000  \n 1st Qu.:0.00000   1st Qu.: 0.0000   1st Qu.:0.0000   1st Qu.: 0.0000  \n Median :0.00000   Median : 0.0000   Median :0.0000   Median : 0.0000  \n Mean   :0.04367   Mean   : 0.1323   Mean   :0.0461   Mean   : 0.0792  \n 3rd Qu.:0.00000   3rd Qu.: 0.0000   3rd Qu.:0.0000   3rd Qu.: 0.0000  \n Max.   :7.14000   Max.   :14.2800   Max.   :3.5700   Max.   :20.0000  \n       re               edu              table            conference      \n Min.   : 0.0000   Min.   : 0.0000   Min.   :0.000000   Min.   : 0.00000  \n 1st Qu.: 0.0000   1st Qu.: 0.0000   1st Qu.:0.000000   1st Qu.: 0.00000  \n Median : 0.0000   Median : 0.0000   Median :0.000000   Median : 0.00000  \n Mean   : 0.3012   Mean   : 0.1798   Mean   :0.005444   Mean   : 0.03187  \n 3rd Qu.: 0.1100   3rd Qu.: 0.0000   3rd Qu.:0.000000   3rd Qu.: 0.00000  \n Max.   :21.4200   Max.   :22.0500   Max.   :2.170000   Max.   :10.00000  \n    CsemiCol            Cpar           Ccroch           Cexclam       \n Min.   :0.00000   Min.   :0.000   Min.   :0.00000   Min.   : 0.0000  \n 1st Qu.:0.00000   1st Qu.:0.000   1st Qu.:0.00000   1st Qu.: 0.0000  \n Median :0.00000   Median :0.065   Median :0.00000   Median : 0.0000  \n Mean   :0.03857   Mean   :0.139   Mean   :0.01698   Mean   : 0.2691  \n 3rd Qu.:0.00000   3rd Qu.:0.188   3rd Qu.:0.00000   3rd Qu.: 0.3150  \n Max.   :4.38500   Max.   :9.752   Max.   :4.08100   Max.   :32.4780  \n    Cdollar            Cdiese             CapLM             CapLsup       \n Min.   :0.00000   Min.   : 0.00000   Min.   :   1.000   Min.   :   1.00  \n 1st Qu.:0.00000   1st Qu.: 0.00000   1st Qu.:   1.588   1st Qu.:   6.00  \n Median :0.00000   Median : 0.00000   Median :   2.276   Median :  15.00  \n Mean   :0.07581   Mean   : 0.04424   Mean   :   5.191   Mean   :  52.17  \n 3rd Qu.:0.05200   3rd Qu.: 0.00000   3rd Qu.:   3.706   3rd Qu.:  43.00  \n Max.   :6.00300   Max.   :19.82900   Max.   :1102.500   Max.   :9989.00  \n    CapLtot       \n Min.   :    1.0  \n 1st Qu.:   35.0  \n Median :   95.0  \n Mean   :  283.3  \n 3rd Qu.:  266.0  \n Max.   :15841.0  \n```\n:::\n:::\n\n:::\n\n**Question 2:** On propose de logtransformer les données. Vérifiez l'impacte de cette normalisation\n\n\n::: {.cell}\n\n```{.r .cell-code}\nLspam<-data.frame(\"spam\"=spam[,1],log(1+spam[,2:58]))\n# A COMPLETER\n```\n:::\n\n\n\n:::{.callout-note custom-style=\"correction\" appearance=\"simple\" title=\"Correction\"}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nLspam<-data.frame(\"spam\"=spam[,1],log(1+spam[,2:58]))\ng1<-ggplot(spam,aes(x=CapLtot))+geom_histogram()\ng2<-ggplot(Lspam,aes(x=CapLtot))+geom_histogram()\ngrid.arrange(g1,g2,ncol=2)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n```\n:::\n\n::: {.cell-output-display}\n![](2526-TP5-MDS-Correction_files/figure-html/unnamed-chunk-31-1.png){width=672}\n:::\n:::\n\n:::\n\n\n**Question 3:** Faites une ACP des données transformées et commentez. \n\n\n::: {.cell}\n\n```{.r .cell-code}\nresPCA<-PCA(...)\n# A COMPLETER\n```\n:::\n\n\n:::{.callout-note custom-style=\"correction\" appearance=\"simple\" title=\"Correction\"}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nresPCA<-PCA(spam,scale.unit = T,quali.sup = 1,graph=F)\nfviz_eig(resPCA)\n```\n\n::: {.cell-output-display}\n![](2526-TP5-MDS-Correction_files/figure-html/unnamed-chunk-33-1.png){width=672}\n:::\n\n```{.r .cell-code}\nfviz_pca_ind(resPCA,habillage=1,geom=c(\"point\"))\n```\n\n::: {.cell-output-display}\n![](2526-TP5-MDS-Correction_files/figure-html/unnamed-chunk-33-2.png){width=672}\n:::\n\n```{.r .cell-code}\nfviz_pca_var(resPCA)\n```\n\n::: {.cell-output-display}\n![](2526-TP5-MDS-Correction_files/figure-html/unnamed-chunk-33-3.png){width=672}\n:::\n\n```{.r .cell-code}\ncorrplot(resPCA$var$cor[,1:4],method=\"ellipse\")\n```\n\n::: {.cell-output-display}\n![](2526-TP5-MDS-Correction_files/figure-html/unnamed-chunk-33-4.png){width=672}\n:::\n:::\n\n:::\n\n**Question 4:** On cherche à mieux comprendre les variables. On considère la dissimilarité suivante entre deux variables $X^{(i)}$ et $X^{(j)}$ basée sur la corrélation. Faites une représentation par positionnement multidimensionnel (MDS) des variables. \n\n$$\nd_{ij} = \\sqrt{2(1- \\mbox{cor}(X^{(i)},X^{(j)})^2)}\n$$\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# A COMPLETER\n```\n:::\n\n\n:::{.callout-note custom-style=\"correction\" appearance=\"simple\" title=\"Correction\"}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrS = cor(Lspam[,2:58])\ndS2=sqrt(2*(1-rS^2))\nmdsspam<-cmdscale(as.dist(dS2),eig=T,add=F)\nggplot(data.frame(x=1:57,y=mdsspam$eig),aes(x=x,y=y))+\n  geom_point()+\n  geom_line()\n```\n\n::: {.cell-output-display}\n![](2526-TP5-MDS-Correction_files/figure-html/unnamed-chunk-35-1.png){width=672}\n:::\n\n```{.r .cell-code}\nautoplot(mdsspam,label=T)\n```\n\n::: {.cell-output-display}\n![](2526-TP5-MDS-Correction_files/figure-html/unnamed-chunk-35-2.png){width=672}\n:::\n:::\n\n:::\n\n\n\n\n",
    "supporting": [
      "2526-TP5-MDS-Correction_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}